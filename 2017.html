<!DOCTYPE html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title> New technologies</title>
</head>
<link rel="stylesheet" href="styles.css" type="text/css">
<body>
        <div class="banner">
            <img class = "banner-image" src="images/PA2017-Blog-1.jpg" alt=""/>            
              </div>
     <div class="about">
    <div class="about-column" id="post-container">
         <div class="wrap-col">
        <div class="post">
            <div class="post-margin">                
            <div class="post-avatar">
                <div class="avatar-frame"></div>
                <img alt='' src="images/logo.jpg"  height="70" width="70" /></div>
            
            <h4 class="post-title">Tesla Autopilot</h4>
                <div class="clear"></div>
            </div>
            
                <div class="main-image">
                <img src="images/ma16-10tesla-1.jpg" id="main-imgs"/>    
                </div>
                            
        <div class="post-margin">
            <p><b>In October 2014, Elon Musk’s electric-car company began rolling out</b> sedans with a dozen ultrasonic sensors discreetly placed around both bumpers and sides.
                 For an additional $4,250, Tesla customers could purchase a “technology package” that used the sensors, as well as a camera, a front radar, and digitally controlled brakes, to help avoid collisions—essentially allowing the car to take over and stop before crashing. But mostly, the hardware sat there, waiting, waiting, and gathering reams of data. A year later, last October 14, the company sent a software update to the 60,000 sensor-laden cars it had sold in that time. 
                The software update was officially named Tesla Version 7.0, but its nickname—Autopilot—was what stuck.
                <br>It did in fact give drivers something similar to what airline pilots employ in flight. The car could manage its speed, steer within and even change lanes, and park itself. Some of these features, like automatic parallel parking, were already on offer from other car companies (including Mercedes, BMW, and General Motors), but the self-steering was suddenly, overnight, via a software update, a giant leap toward full autonomy.
                <br>
                <br>Tesla customers, delighted, posted videos of themselves on the highway, hands free, reading the paper, sipping coffee, and even, once, riding on the roof. Some of these are, it’s worth pointing out, illegal acts. Autopilot existed in a legal gray area,  but it was a grand gesture toward an ever nearing future, one that will reshape not just the car and our relationship with it but the road and our entire transportation infrastructure.
                <br>
                <br>Which is why I jumped at the chance to borrow a car with Autopilot for a few days and drive it—or let it drive me—around Los Angeles.
                <br>Everyone wanted to know what it felt like, the strange surrender of allowing a car to take control. The only moments that seemed like magic were when the car parked itself or changed lanes, mostly because watching a steering wheel turn all on its own was unnatural and ghostly. Other than that, I was amazed by how quickly I got used to it, how inevitable it began to feel. As a Tesla engineer told me—on condition of anonymity, because the company won’t let anyone but Musk speak publicly these days—the thing that quickly becomes strange is driving a car without Autopilot. “You’ll feel like the car is not doing its job,” he said. 
                <br>The car can’t start in Autopilot; it requires a set of circumstances (good data, basically) before you can engage the setting. These include clear lane lines, a relatively constant speed, a sense of the cars around you, and a map of the area you’re traveling through—roughly in that order. L.A.’s abundant highway traffic is the ideal scenario for Autopilot, not simply because of all the data it makes available to the ultrasonic sensors—which use high-frequency sound waves to identify objects up to 16 feet away—but also because humans are awful in traffic. We are bad at estimating distances to begin with, and we are constantly trying to switch lanes when the next one looks faster, causing accidents in the process. With Autopilot, I no longer had to stare at the bumper ahead of me, and I could look around to see the variety of bad decisions drivers make, stopping and starting and stopping again. Meanwhile, my car accelerated and slowed more smoothly than it ever could have with me in charge.
                <br>With its incremental approach, Tesla stands in contrast to Google and other companies that have small test fleets gathering data in hopes of someday launching fully autonomous cars. For Tesla, its customers and their partially autonomous cars are a widely distributed test fleet. The hardware required for true autonomy is already in place, so the transition can play out in software updates. Musk has said that could be technically feasible—if not legally so—within two years.
                <br>
                <br>The day after I returned the Tesla, my fiancée and I were on an L.A. freeway and saw someone, speeding, cross three lanes, cutting in front of several drivers. As the traffic stopped, the car behind us came in way too fast and crashed into our bumper, which fell right off. The future, I thought, was practically here, and it couldn’t arrive soon enough.
            </p>
        </div> 
        <div class="clear"></div>
        </div>
         
    <div class="clear"></div>
    </div>
    </div>
</div></div>  

<div class="about-column" id="post-container">
        <div class="wrap-col">
       <div class="post">
           <div class="post-margin">                
           <div class="post-avatar">
               <div class="avatar-frame"></div>
               <img alt='' src="images/logo.jpg"  height="70" width="70" /></div>
           
           <h4 class="post-title">Robots That Teach Each Other</h4>
               <div class="clear"></div>
           </div>
           
               <div class="main-image">
               <img src="images/ma1610robobrainv2x2760.jpg" id="main-imgs"/>    
               </div>
                           
       <div class="post-margin">
           <p><b>Many of the jobs humans would like robots to perform,</b> such as packing items in warehouses, assisting bedridden patients, 
            or aiding soldiers on the front lines, aren’t yet possible because robots still don’t recognize and easily handle common objects. People generally have no trouble folding socks or picking up water glasses, because we’ve gone through “a big data collection process” called childhood, says Stefanie Tellex, a computer science professor at Brown University. For robots to do the same types of routine tasks, they also need access to reams of data on how to grasp and manipulate objects. Where does that data come from? Typically it has come from painstaking programming. 
            But ideally, robots could get some information from each other.
            <br>That’s the theory behind Tellex’s “Million Object Challenge.” The goal is for research robots around the world to learn how to spot and handle simple items from bowls to bananas, upload their data to the cloud, and allow other robots to analyze and use the information.
            <br>
            <br>Tellex’s lab in Providence, Rhode Island, has the air of a playful preschool. On the day I visit, a Baxter robot, an industrial machine produced by Rethink Robotics, stands among oversized blocks, scanning a small hairbrush. It moves its right arm noisily back and forth above the object, taking multiple pictures with its camera and measuring depth with an infrared sensor. Then, with its two-pronged gripper, it tries different grasps that might allow it to lift the brush. Once it has the object in the air, it shakes it to make sure the grip is secure. If so, the robot has learned how to pick up one more thing.
            <br>
            <br>The robot can work around the clock, frequently with a different object in each of its grippers. Tellex and her graduate student John Oberlin have gathered—and are now sharing—data on roughly 200 items, starting with such things as a child’s shoe, a plastic boat, a rubber duck, a garlic press and other cookware, and a sippy cup that originally belonged to her three-year-old son. Other scientists can contribute their robots’ own data, and Tellex hopes that together they will build up a library of information on how robots should handle a million different items. Eventually, robots confronting a crowded shelf will be able to “identify the pen in front of them and pick it up,” Tellex says.
            <br>
            <br>Projects like this are possible because many research robots use the same standard framework for programming, known as ROS. Once one machine learns a given task, it can pass the data on to others—and those machines can upload feedback that will in turn refine the instructions given to subsequent machines. Tellex says the data about how to recognize and grasp any given object can be compressed to just five to 10 megabytes, about the size of a song in your music library.
            <br>
            <br>Tellex was an early partner in a project called RoboBrain, which demonstrated how one robot could learn from another’s experience. Her collaborator Ashutosh Saxena, then at Cornell, taught his PR2 robot to lift small cups and position them on a table. Then, at Brown, Tellex downloaded that information from the cloud and used it to train her Baxter, which is physically different, to perform the same task in a different environment.
            <br>
            <br>Such progress might seem incremental now, but in the next five to 10 years, we can expect to see “an explosion in the ability of robots,” says Saxena, now CEO of a startup called Brain of Things. As more researchers contribute to and refine cloud-based knowledge, he says, “robots should have access to all the information they need, at their fingertips.”
            </p>
       </div> 
       <div class="clear"></div>
       </div>
        
   <div class="clear"></div>
   </div>
   </div>
</div></div>  
<div class="about-column" id="post-container">
        <div class="wrap-col">
       <div class="post">
           <div class="post-margin">                
           <div class="post-avatar">
               <div class="avatar-frame"></div>
               <img alt='' src="images/logo.jpg"  height="70" width="70" /></div>
           
           <h4 class="post-title">Immune Engineering</h4>
               <div class="clear"></div>
           </div>
           
               <div class="main-image">
               <img src="images/engineeringcellsfinal2.jpg" id="main-imgs"/>    
               </div>
                           
       <div class="post-margin">
           <p>
                The doctors looking at Layla Richards saw a little girl with leukemia bubbling in her veins. She’d had bags and bags of chemotherapy and a bone marrow transplant. But the cancer still thrived. By last June, the 12-month-old was desperately ill. Her parents begged—wasn’t there anything?
                <br>
                <br>There was. In a freezer at her hospital—Great Ormond Street, in London—sat a vial of white blood cells. The cells had been genetically altered to hunt and destroy leukemia, but the hospital hadn’t yet sought permission to test them. They were the most extensively engineered cells ever proposed as a therapy, with a total of four genetic changes, two of them introduced by the new technique of genome editing.
                <br>Soon a doctor from Great Ormond was on the phone to Cellectis, a biotechnology company with French roots that is now located on the East Side of Manhattan. The company owned the cancer treatment, which it had devised using a gene-editing method called TALENs, a way of making cuts and fixes to DNA in living cells. “We got a call. The doctors said, ‘We’ve got a girl who is out of T cells and out of options,’” André Choulika, the CEO of Cellectis, remembers. “They wanted one of the vials made during quality-control testing.”
                <br>
                <br>The doctors hoped to make Layla a “special,” a patient who got the drug outside a clinical trial. It was a gamble, since the treatment had been tried only in mice. If it failed, the company’s stock and reputation could tank, and even if it succeeded, the company might get in trouble with regulators. “It was saving a life versus the chance of bad news,” Choulika says.
                <br>Cellectis began developing the treatment in 2011 after doctors in New York and Philadelphia reported that they’d found a way to gain control over T cells, the so-called killer cells of the immune system. They had shown that they could take T cells from a person’s bloodstream and, using a virus, add new DNA instructions to aim them at the type of blood cell that goes awry in leukemia. The technique has now been tested in more than 300 patients, with spectacular results, often resulting in complete remission. A dozen drug firms and biotechnology companies are now working to bring such a treatment to market.
                <br>The T cells created by Cellectis could have even broader applications. The previous treatments use a person’s own cells. But some patients, especially small children like Layla, don’t have enough T cells.
                <br>Foreseeing this problem, Cellectis had set out to use gene editing to create a more highly engineered but ultimately simpler “universal” supply of T cells made from the blood of donors. The company would still add the new DNA, but it would also use gene editing to delete the receptor that T cells normally use to sniff out foreign-looking molecules.
                <br>
                <br>“The T cell has a huge potential for killing. But the thing you can’t do is inject T cells from Mr. X into Mr. Y,” Choulika says. “They’d recognize Mr. Y as ‘non-self’ and start firing off at everything, and the patient will melt down.” But if the T cells are stripped down with gene editing, like the ones that were sitting in Great Ormond’s freezer, that risk is mostly eliminated. Or so everyone hoped.
                <br>
                <br>In November, Great Ormond announced that Layla was cured. The British press jumped on the heartwarming story of a brave kid and daring doctors. Accounts splashed on front pages sent Cellectis’s stock price shooting upward. Two weeks later, the drug companies Pfizer and Servier announced they would ante up $40 million to purchase rights to the treatment. 
                <br>
                <br>Although many of the details of Layla’s case have yet to be disclosed, and some cancer experts say the role of the engineered T cells in her cure remains murky, her recovery pointed a spotlight on “immune engineering,” and on the way that advances in controlling and manipulating the immune system are leading to unexpected breakthroughs in cancer treatment. They also could lead to new treatments for HIV and autoimmune diseases like arthritis and multiple sclerosis.
                <br>
                The human immune system has been called nature’s “weapon of mass destruction.” It has a dozen major cell types, including several kinds of T cells. It defends against viruses it’s never seen before, suppresses cancer (though not always), and for the most part manages to avoid harming the body’s own tissue. It even has a memory, which is the basis of all vaccines.
                <br>More than 100 years ago, the American surgeon William Coley observed that an unexpected infection could sometimes make a tumor evaporate. Subsequently, Coley injected streptococcal cultures into cancer patients and saw the tumors shrink in some cases. The finding, published in 1893, showed the immune system could confront and fight cancer—but how did it work? Until recently, the answers weren’t known, and cancer immunotherapy was seen as a failed idea. 
                <br>But scientists have gradually mapped the network of molecules that govern how the immune system interacts with a tumor. And over the last few years, these insights have allowed drug companies and labs to start tinkering with the immune system’s behavior. “From 40 years and more of science, we know the general nature of the conversation between the tumor cells and the immune system,” says Philip Sharp, a biologist at MIT’s Koch Institute for Integrative Cancer Research and a recipient of the 1993 Nobel Prize in medicine. “That’s the conversation we’re trying to join in order to have a therapeutic effect. We are still at the level of a five-year-old kid. We know there are nouns, and that there are verbs. But the diversity of the vocabulary is still being mapped out.”
             </p>
       </div> 
       <div class="clear"></div>
       </div>
        
   <div class="clear"></div>
   </div>
   </div>
</div></div>  
<div class="clear"></div>
</div>
</body>